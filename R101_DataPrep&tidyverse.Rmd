---
title: "Data Preparation and Preprocessing (Chapter 11,12,13,14)"
author: "Xing Song"
date: "10/01/2020"
output: html_document
---

Let's do some preparation for the class by running the following chunk of codes:

```{r setup}
#set up rmd print-out style
knitr::opts_chunk$set(message=F,warning=F,fig.width=6, fig.height=3)

#load packages
# install.packages("tidyverse") #note: tidyverse is a group of packages
pacman::p_load(tidyverse)
```


```{r db_connection}
config_file<-read.csv("config.csv",stringsAsFactors = F)
drv<-RJDBC::JDBC(driverClass="oracle.jdbc.OracleDriver",
                 classPath="./ojdbc6.jar")
url<-paste0("jdbc:oracle:thin:@localhost:1521:",config_file$database)
conn <- RJDBC::dbConnect(drv=drv,
                         url=url, 
                         user=config_file$username, 
                         password=config_file$password)
```


```{sql, connection=conn, output.var="idd_pt"}
select * from XSONG.PRVM_IDD_PATIENT_VIEW
```


**************************************************************************************************
**************************************************************************************************

## Quantitative and Qualitative Data (11.2.3)

#### Qualitative Data

* also called "categorical data", which cannot be expressed numerically     

  * nominal: when there is no natural ordering among the categories (e.g. sex, race)    

```{r nom_data}
ggplot(idd_pt,aes(x=RACE))+
  geom_histogram(stat="count")
```

  * ordinal: when there is a natural ordering among the categories (e.g. age_group, grades) 


```{r ord_data}
##==============================================
# "mutate" function for adding/altering columns
# "case_when" function
##==============================================

#add a new column, "age_group", that groups ages into 4 groups
idd_pt_add_agegrp<-idd_pt %>%
  mutate(age_group=case_when(AGE<10~'Group1',
                             AGE>=10&AGE<15~'Group2',
                             AGE>=15&AGE<20~'Group3',
                             AGE>=20~'Group4'))
#print first 6 rows
head(idd_pt_add_agegrp)

#plot out the age group
ggplot(idd_pt_add_agegrp,aes(x=age_group))+
  geom_histogram(stat="count")
```



**********************************                     

#### Quantitative Data
* can be measured, written down with numbers and manipulated numerically (i.e. age, BMI, blood pressure, variety of labs)   
  * discrete: data that can only taken certain values (e.g. number of visits)   
  * continuous: data tha can take any values (e.g. age, weights)    
    
```{r cont_dat}
ggplot(idd_pt,aes(x=AGE))+
  geom_density(fill="blue")

#5-number summary
summary(idd_pt$AGE)
```

**************************************************************************************************
**************************************************************************************************

## Data Preprocessing (Chapter 12, 13, 14)

* A series of steps to transform raw data into a **"clean"** and **"tidy"** dataset prior to statistical analysis
* EHR data were collected for clinical and billing purposes, not necessarily for research purposes
* Preprcoessing aims at improving the quality of data to allow for reliable statistical analysis
* General steps for data preprocessing are **Data Integration**, **Data Abstraction**, **Data Cleaning**, **Data Transformation** and **Data Reducton**. 

**************************************************************************************************
**************************************************************************************************

### Data Integration
* A process of combining data derived from various data sources (e.g. databases, flat files, tables) into a consistent dataset
* One example as we have exercised in SQL is for you to create mini-tables for a subset of variables and then join them together
* This step can be accomplished in any analytical software available on greenheron (e.g. SQL, R, SAS, STAT, Python), but we usually recommend SQL for its efficiency


*Working example: I want to examine if there is a significant difference of BMI among the three groups of adult patients: just down, just autism, and both*

```{sql integrate_data,connection = conn,output.var="asd_down_bmi"}
with both_dx1 as (
select d.patient_num
      ,c.code_label
      ,min(start_date) first_dxdt
from prvm_idd_data_view d
join prvm_idd_code_info_view c
on d.code = c.code
where lower(c.code_label) like '%down%' or 
      lower(c.code_label) like '%autism%'
group by d.patient_num, c.code_label
),
     either_dx1 as (
select patient_num, min(first_dxdt) first_dxdt
from both_dx1
group by patient_num
),
     down_dx1 as (
select patient_num, min(first_dxdt) down_onset
from both_dx1
where lower(code_label) like '%down%'
group by patient_num
),
     autism_dx1 as (
select patient_num, min(first_dxdt) autism_onset
from both_dx1
where lower(code_label) like '%autism%'
group by patient_num
),
     bmi as (
select dat.patient_num, to_number(dat.nval) as bmi, dat.start_date as bmi_date
from prvm_idd_data_view dat
where exists (select 1 from prvm_idd_code_info_view cd
              where cd.code = dat.code and
                    lower(cd.code_label) like '%mass%') 
)
select e.patient_num
      ,p.birth_date
      ,p.sex
      ,p.race
      ,p.death_date
      ,d.down_onset
      ,a.autism_onset
      ,round((a.autism_onset-p.birth_date)/365.25) age_at_autism
      ,round((d.down_onset-p.birth_date)/365.25) age_at_down
      ,round((e.first_dxdt-p.birth_date)/365.25) age_at_firstdx
      ,case when a.autism_onset is not null and d.down_onset is not null then 'both'
            when a.autism_onset is not null and d.down_onset is null then 'autism'
            when d.down_onset is not null and a.autism_onset is null then 'down'
       end as diagnosis
      ,bmi.bmi
      ,bmi.bmi_date
from either_dx1 e
join prvm_idd_patient_view p on e.patient_num = p.patient_num
left join down_dx1 d on e.patient_num = d.patient_num 
left join autism_dx1 a on e.patient_num = a.patient_num
left join bmi on e.patient_num = bmi.patient_num
where bmi.bmi_date >= least (coalesce(a.autism_onset,current_date),
                               coalesce(d.down_onset,current_date))
order by e.patient_num, bmi.bmi_date
```

Note that we only want to include *adult* patients, let's do a quick cleaning up:

```{r}
##==============================================
# "filter" function for subsetting rows satifying 
#  certain criteria
##==============================================
asd_down_bmi<-asd_down_bmi %>%
  filter(AGE_AT_FIRSTDX >= 18)
```

Let's take a look at few rows of this integarted `asd_down_bmi` data table:

```{r}
##==============================================
# "slice" function for subsetting rows
##==============================================
# only select the first 10 rows
asd_down_bmi %>% slice(1:10)
```


**************************************************************************************************
**************************************************************************************************

### Data Abstraction
As you can see, there are still multiple rows for the same patient due to multiple BMI records. To get a analytic set with one patient observation per row, we need to perform a data processing step called "data abstraction". "Data abstraction" is usually needed when repeated measurement of the same variable exists (e.g. multiple bmi records over time), and we want to remove some physical, spacial or temporal details in order to focus attention on information with higher importance (e.g. we use average/mean bmi before cardiovascular disease onset to capture the core information about the patient's unhealthy weight status)

There are many different methods for data abstractions, which can be as simple as "using the first observation" or "taking the average", or as complex as "feature extraction using principle component analysis (PCA)" or "building a markov chain". Which method to use really depends on your research context and feasibility consideration. 

We will demonstrate a simple data abstraction method in R, which can also be achieved in SQL

```{r get_median_bmi}
##====================================================
# "group_by" and "summarize" function for summarizing 
#  variables according to certain grouping criteria and
#  functions of interests
##======================================================
asd_down_bmi_median<-asd_down_bmi %>%
  mutate(BMI=as.numeric(BMI)) %>%
  group_by(PATIENT_NUM,SEX,RACE,AGE_AT_FIRSTDX,DIAGNOSIS) %>%
  summarize(bmi_med = median(BMI,na.rm=T)) %>%
  ungroup
```


```{r}
##====================================================
# "sampl_n" function for randomly sampling n rows 
##=====================================================
asd_down_bmi_median %>% sample_n(5)
```


**************************************************************************************************
**************************************************************************************************

### Data Transformation

The aim of data transformation is to transform the data values into a format, scale or unit that is more suitable for analysis


#### Encoding Categorical Data

Since what will be eventually fed into any statistical test or analysis model should be numerical values, it is essential to transform categorical data into a numerical representations, i.e. a set of indicators for each category, which is called "one-hot-encoding"

For example, in our example, the sex and race are categorical variables, which we would want to perform one-hot encoding on:

```{r encode_sex}
sex_ohe<-asd_down_bmi_median %>% 
  dplyr::select(PATIENT_NUM,SEX) %>%
  mutate(sex_f_ind=case_when(SEX =="f" ~ 1,
                             TRUE ~ 0))

head(sex_ohe)
```


```{r encode_race}
race_ohe<-asd_down_bmi_median %>% 
  dplyr::select(PATIENT_NUM,RACE) %>%
  mutate(ind=1) %>%
  spread(RACE,ind, fill = 0)

head(race_ohe)
```

**************************************************************************************************

#### Discretizing Numerical Data

Sometimes, it is a good strategy to **discretize** numerical data into value groups ("Binning"). For example, instead of using BMI values, we may want to categorize them into weight groups. This could help improve interpretability of your model, control overfitting, and remove outliers.

This is the same exercise as we did in Homework 3:

```{r}
bmi_cat<-asd_down_bmi_median %>% 
  dplyr::select(PATIENT_NUM,DIAGNOSIS, bmi_med) %>%
  mutate(bmi_classify = case_when(bmi_med < 18.5 ~ 'under',
                                  bmi_med < 25 ~ 'normal',
                                  bmi_med < 30 ~ 'over',
                                  bmi_med >= 30 ~ 'obese'))
```

**************************************************************************************************

#### Normalization 

Generaly means data for a numerical variable are scaled in order to range between a specified set of values, such as 0 - 1. 
* mean-sd scaling: (x-m)/s, where m is the mean and s is the sample standard deviations
* min-max scaling: (x-min)/(min-max)

```{r bmi_norm, fig.width=10, fig.height=4}
bmi_m<-mean(bmi_cat$bmi_med,na.rm=T)
bmi_sd<-sd(bmi_cat$bmi_med,na.rm=T)
bmi_min<-min(bmi_cat$bmi_med,na.rm=T)
bmi_max<-max(bmi_cat$bmi_med,na.rm=T)

bmi_cat_norm<-bmi_cat %>%
  mutate(norm_m_sd=(bmi_med-bmi_m)/bmi_sd,
         norm_min_max=(bmi_med-bmi_min)/(bmi_max-bmi_min)) %>%
  select(bmi_med,norm_m_sd,norm_min_max) %>%
         gather(var,val)

ggplot(bmi_cat_norm,aes(y=val))+
  geom_boxplot()+
  facet_wrap(~var,scales = "free",nrow=1)

```

**************************************************************************************************

#### Aggregation/Generalization/Reduction

Two or more values of the same attribute (but with different labels) are aggregated into one value. For example, "@" and "declined" are used as different categories for race:

```{r race}
table(asd_down_bmi_median$RACE)
```

And you may want to group them together as a single "unknown" category:

```{r race_agg}
asd_down_bmi_median<-asd_down_bmi_median %>%
  mutate(RACE=case_when(RACE %in% c("@","declined") ~ "unknown",
                        TRUE ~ RACE))
table(asd_down_bmi_median$RACE)
```

Sometime, you may want to aggregate low level attributes into higher level ones. For example, cardiovascular disease are recorded as multiple lower-level diagnosis codes in EHR, which may need to be aggregated. However, there may also be times when you want to keep such granularity. 

```{sql, connection=conn}
select variable, count(distinct code)
from prvm_idd_code_info_view
where lower(variable) like '%heart%'
group by variable
```

There are also some statistical approaches to aggregate the variables in a more systemic fashion (e.g. principal component analysis, latent factor analysis), which are usually used in high-dimensional data (i.e. more than hundreds of variables). However, such approaches may impair the interpretability of your model. We may re-visit this topic with more details when we come across with analysis involving high-dimensional data.    






